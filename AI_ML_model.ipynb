{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_logs = pd.read_csv(\"synthetic_query_logs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_logs.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "query_logs = pd.read_csv(\"synthetic_query_logs.csv\")\n",
    "\n",
    "# Select the columns to normalize\n",
    "features_to_normalize = ['execution_time', 'bytes_scanned', 'complexity_score']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the features\n",
    "query_logs[features_to_normalize] = scaler.fit_transform(query_logs[features_to_normalize])\n",
    "\n",
    "# View the normalized data\n",
    "print(query_logs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the AI Model\n",
    "* Label Data for Suboptimal Queries\n",
    "\n",
    "* Defining of suboptimal queries as those with:\n",
    "execution_time > 10 seconds\n",
    "efficiency_score < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_logs['label'] = ((query_logs['execution_time'] > 10) | (query_logs['efficiency_score'] < 0.1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define features and target\n",
    "X = query_logs[['execution_time', 'bytes_scanned', 'complexity_score']]\n",
    "y = query_logs['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean?\n",
    "\n",
    "Precision tells you how many of the predicted positives were actually positive.\n",
    "Recall tells you how many of the actual positives were correctly identified.\n",
    "F1-Score gives a balanced measure considering both precision and recall.\n",
    "Accuracy measures overall correct predictions.\n",
    "Macro avg and Weighted avg provide averages for all classes, with the weighted average considering class imbalances.\n",
    "\n",
    "\n",
    "In this case, the model has slightly better performance for class 0 (precision and recall of 0.83) compared to class 1 (precision and recall of 0.75), which is reflected in the overall accuracy and averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Rules for Optimization\n",
    "High Execution Time\n",
    "\n",
    "Condition: execution_time > 10 seconds\n",
    "Recommendation: Suggest query optimization techniques like creating indexes or optimizing joins.\n",
    "Low Efficiency Score\n",
    "\n",
    "Condition: efficiency_score < 0.1\n",
    "Recommendation: Reduce the number of bytes scanned by introducing partitioning or clustering for large datasets.\n",
    "No Issues Detected\n",
    "\n",
    "Condition: Neither of the above conditions is met.\n",
    "Recommendation: The query is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations based on rules\n",
    "def generate_recommendation(row):\n",
    "    if row['execution_time'] > 10:\n",
    "        return \"Optimize query structure (e.g., create indexes or optimize joins)\"\n",
    "    elif row['efficiency_score'] < 0.1:\n",
    "        return \"Consider clustering or partitioning to reduce bytes scanned\"\n",
    "    else:\n",
    "        return \"Query is optimal\"\n",
    "\n",
    "# Apply recommendations to the dataset\n",
    "query_logs['recommendation'] = query_logs.apply(generate_recommendation, axis=1)\n",
    "\n",
    "# Display the dataset with recommendations\n",
    "print(query_logs[['query_id', 'execution_time', 'efficiency_score', 'recommendation']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dashboard\n",
    "\n",
    "First install streamlit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an streamlit.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Load query logs\n",
    "query_logs = pd.read_csv(\"synthetic_query_logs.csv\")\n",
    "\n",
    "# Display data\n",
    "st.title(\"AI-Enhanced Query Optimization\")\n",
    "st.write(\"Explore recommendations for improving query efficiency.\")\n",
    "st.dataframe(query_logs[['query_id', 'execution_time', 'efficiency_score', 'recommendation']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "streamlit run streamlit_app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
